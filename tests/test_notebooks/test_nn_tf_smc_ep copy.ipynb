{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing EagerPy implementation of H-SMC on MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stat\n",
    "import numpy as np\n",
    "import eagerpy as ep\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "import GPUtil\n",
    "import foolbox as fb\n",
    "import cpuinfo\n",
    "import pandas as pd\n",
    "from stat_reliability_measure.dev.utils import str2bool,str2floatList,str2intList,float_to_file_float,dichotomic_search,datasets_dims,datasets_num_c\n",
    "from scipy.special import betainc\n",
    "from importlib import reload\n",
    "from stat_reliability_measure.home import ROOT_DIR\n",
    "from stat_reliability_measure.dev.tf_utils import dic_in_shape_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stat_reliability_measure.dev.smc.smc_ep as smc_ep\n",
    "import stat_reliability_measure.dev.ep_utils as e_u\n",
    "import stat_reliability_measure.dev.smc.smc_pyt as smc_pyt\n",
    "import stat_reliability_measure.dev.tf_utils as tf_u\n",
    "import stat_reliability_measure.dev.utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stat_reliability_measure.dev.utils' from '/home/karim-tito/stat_reliability_measure/dev/utils.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(smc_ep)\n",
    "reload(tf_u)\n",
    "reload(e_u)\n",
    "reload(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name=\"smc_ep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    dataset='mnist'\n",
    "    N=200\n",
    "    N_range=[]\n",
    "    T=10\n",
    "    T_range=[]\n",
    "    L=5\n",
    "    L_range=[]\n",
    "    min_rate=0.2\n",
    "    \n",
    "    alpha=0.2\n",
    "    alpha_range=[]\n",
    "    ess_alpha=0.875\n",
    "    e_range=[]\n",
    "   \n",
    "    n_rep=150\n",
    "    \n",
    "    save_config=False \n",
    "    print_config=True\n",
    "    \n",
    "    x_min=0\n",
    "    x_max=1\n",
    "    x_mean=0\n",
    "    x_std=1\n",
    "\n",
    "    epsilons = None\n",
    "    eps_max=0.3\n",
    "    eps_min=0.2\n",
    "    eps_num=5\n",
    "    model_arch='CNN_custom'\n",
    "    model_path=None\n",
    "    export_to_onnx=False\n",
    "    use_attack=False\n",
    "    attack='PGD'\n",
    "    lirpa_bounds=False\n",
    "    download=True\n",
    "    train_model=False\n",
    "    \n",
    "    \n",
    "    noise_dist='uniform'\n",
    "    d=None\n",
    "    verbose=0\n",
    "    log_dir=None\n",
    "    aggr_res_path = None\n",
    "    update_agg_res=False\n",
    "    sigma=1\n",
    "    v1_kernel=True\n",
    "    torch_seed=None\n",
    "    gpu_name=None\n",
    "    cpu_name=None\n",
    "    cores_number=None\n",
    "    track_gpu=False\n",
    "    track_cpu=False\n",
    "    \n",
    "    n_max=10000 \n",
    "    allow_multi_gpu=False\n",
    "    tqdm_opt=True\n",
    "    allow_zero_est=True\n",
    "    track_accept=True\n",
    "    track_calls=False\n",
    "    mh_opt=False\n",
    "    adapt_dt=False\n",
    "    adapt_dt_mcmc=False\n",
    "    target_accept=0.574\n",
    "    accept_spread=0.1\n",
    "    dt_decay=0.999\n",
    "    dt_gain=None\n",
    "    dt_min=1e-5\n",
    "    dt_max=0.7\n",
    "    v_min_opt=True\n",
    "    ess_opt=False\n",
    "    only_duplicated=True\n",
    "    np_seed=None\n",
    "    lambda_0=0.5\n",
    "    test2=False\n",
    "\n",
    "    s_opt=False\n",
    "    s=1\n",
    "    clip_s=True\n",
    "    s_min=1e-3\n",
    "    s_max=3\n",
    "    s_decay=0.95\n",
    "    s_gain=1.0001\n",
    "\n",
    "    track_dt=False\n",
    "    mult_last=True\n",
    "    linear=True\n",
    "\n",
    "    track_ess=True\n",
    "    track_beta=True\n",
    "    track_dt=True\n",
    "    track_v_means=True\n",
    "    track_ratios=False\n",
    "\n",
    "    kappa_opt=True\n",
    "\n",
    "    adapt_func='ESS'\n",
    "    M_opt = False\n",
    "    adapt_step=True\n",
    "    FT=True\n",
    "    sig_dt=0.02\n",
    "\n",
    "    batch_opt=True\n",
    "    track_finish=False\n",
    "    lirpa_cert=False\n",
    "    robust_model=False\n",
    "    robust_eps=0.1\n",
    "    load_batch_size=100 \n",
    "    nb_epochs= 10\n",
    "    adversarial_every=1\n",
    "    data_dir=ROOT_DIR+\"/data\"\n",
    "    p_ref_compute=False\n",
    "    input_start=0\n",
    "    input_stop=None\n",
    "\n",
    "    gaussian_latent=True\n",
    "\n",
    "    model_dir=None \n",
    "    L_min=1\n",
    "    GK_opt=False\n",
    "    GV_opt=False\n",
    "    g_target=0.8\n",
    "    skip_mh=False\n",
    "    force_train=False\n",
    "    killing=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reliability experiments on architecture CNN_custom trained on mnist.\n",
      "Testing uniform noise pertubatin with epsilon in [0.2        0.22133638 0.24494897 0.2710806  0.3       ]\n"
     ]
    }
   ],
   "source": [
    "if config.model_dir is None:\n",
    "    config.model_dir=os.path.join(ROOT_DIR+\"/models/\",config.dataset)\n",
    "    if not os.path.exists(config.model_dir):\n",
    "        os.mkdir(config.model_dir)\n",
    "\n",
    "config.d = u.datasets_dims[config.dataset]\n",
    "color_dataset=config.dataset in ('cifar10','cifar100','imagenet') \n",
    "#assert config.adapt_func.lower() in smc_pyt.supported_beta_adapt.keys(),f\"select adaptive function in {smc_pyt.supported_beta_adapt.keys}\"\n",
    "#adapt_func=smc_pyt.supported_beta_adapt[config.adapt_func.lower()]\n",
    "\n",
    "if config.adapt_func.lower()=='simp_ess':\n",
    "    adapt_func = lambda beta,v : smc_pyt.nextBetaSimpESS(beta_old=beta,v=v,lambda_0=config.lambda_0,max_beta=1e6)\n",
    "elif config.adapt_func.lower()=='simp':\n",
    "    adapt_func = lambda beta,v: smc_pyt.SimpAdaptBetaPyt(beta,v,config.g_target,v_min_opt=config.v_min_opt)\n",
    "prblm_str=config.dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if len(config.e_range)==0:\n",
    "    config.e_range= [config.ess_alpha]\n",
    "\n",
    "if config.input_stop is None:\n",
    "    config.input_stop=config.input_start+1\n",
    "else:\n",
    "    assert config.input_start<config.input_stop,\"/!\\ input start must be strictly lower than input stop\"\n",
    "if len(config.N_range)==0:\n",
    "    config.N_range= [config.N]\n",
    "\n",
    "if config.noise_dist is not None:\n",
    "    config.noise_dist=config.noise_dist.lower()\n",
    "\n",
    "if config.noise_dist not in ['uniform','gaussian']:\n",
    "    raise NotImplementedError(\"Only uniform and Gaussian distributions are implemented.\")\n",
    "\n",
    "if len(config.T_range)==0:\n",
    "    config.T_range= [config.T]\n",
    "\n",
    "if len(config.L_range)==0:\n",
    "    config.L_range= [config.L]\n",
    "if len(config.alpha_range)==0:\n",
    "    config.alpha_range= [config.alpha]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if config.np_seed is None:\n",
    "    config.np_seed=int(time())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if config.track_gpu:\n",
    "    gpus=GPUtil.getGPUs()\n",
    "    if len(gpus)>1:\n",
    "        print(\"Multi gpus detected, only the first GPU will be tracked.\")\n",
    "    config.gpu_name=gpus[0].name\n",
    "\n",
    "if config.track_cpu:\n",
    "    config.cpu_name=cpuinfo.get_cpu_info()[[key for key in cpuinfo.get_cpu_info().keys() if 'brand' in key][0]]\n",
    "    config.cores_number=os.cpu_count()\n",
    "\n",
    "\n",
    "\n",
    "d=config.d\n",
    "#epsilon=config.epsilon\n",
    "\n",
    "if config.log_dir is None:\n",
    "    config.log_dir=os.path.join(ROOT_DIR+'/logs',config.dataset+'_tests')\n",
    "if not os.path.exists(ROOT_DIR+'/logs'):\n",
    "    os.mkdir(ROOT_DIR+'/logs')  \n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.mkdir(config.log_dir)\n",
    "\n",
    "results_path=os.path.join(config.log_dir,'results.csv')\n",
    "if os.path.exists(results_path):\n",
    "    results_g=pd.read_csv(results_path)\n",
    "else:\n",
    "    results_g=pd.DataFrame(columns=['mean_est','mean_time','mean_err','stdtime','std_est','T','N','rho','alpha','n_rep','min_rate','method'])\n",
    "    results_g.to_csv(results_path,index=False)\n",
    "raw_logs = os.path.join(config.log_dir,'raw_logs/')\n",
    "if not os.path.exists(raw_logs):\n",
    "    os.mkdir(raw_logs)\n",
    "raw_logs_path=os.path.join(config.log_dir,'raw_logs/'+method_name)\n",
    "if not os.path.exists(raw_logs_path):\n",
    "    os.mkdir(raw_logs_path)\n",
    "\n",
    "loc_time= datetime.today().isoformat().split('.')[0]\n",
    "log_name=method_name+'_'+'_'+loc_time\n",
    "exp_log_path=os.path.join(raw_logs_path,log_name)\n",
    "if os.path.exists(path=exp_log_path):\n",
    "    exp_log_path = exp_log_path+'_'+str(np.random.randint(low=0,high=9))\n",
    "os.mkdir(path=exp_log_path)\n",
    "\n",
    "# if config.aggr_res_path is None:\n",
    "#     aggr_res_path=os.path.join(config.log_dir,'agg_res.csv')\n",
    "# else:\n",
    "#     aggr_res_path=config.aggr_res_path\n",
    "\n",
    "if config.dt_gain is None:\n",
    "    config.dt_gain=1/config.dt_decay\n",
    "\n",
    "\n",
    "\n",
    "if config.epsilons is None:\n",
    "    log_min,log_max=np.log(config.eps_min),np.log(config.eps_max)\n",
    "    log_line=np.linspace(start=log_min,stop=log_max,num=config.eps_num)\n",
    "    config.epsilons=np.exp(log_line)\n",
    "\n",
    "param_ranges = [config.N_range,config.T_range,config.L_range,config.e_range,config.alpha_range]\n",
    "param_lens=np.array([len(l) for l in param_ranges])\n",
    "nb_runs= np.prod(param_lens)\n",
    "\n",
    "mh_str=\"adjusted\" \n",
    "method=method_name+'_'+mh_str\n",
    "save_every = 1\n",
    "x_min=0\n",
    "x_max=1\n",
    "#adapt_func= smc_pyt.ESSAdaptBetaPyt if config.ess_opt else smc_pyt.SimpAdaptBetaPyt\n",
    "num_classes=u.datasets_num_c[config.dataset.lower()]\n",
    "print(f\"Running reliability experiments on architecture {config.model_arch} trained on {config.dataset}.\")\n",
    "print(f\"Testing uniform noise pertubatin with epsilon in {config.epsilons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_custom_tf(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10,dataset='mnist'):\n",
    "        super().__init__()\n",
    "        self.input_shape=dic_in_shape_tf[dataset]\n",
    "        self.conv1=nn.Conv2d(filters=32,kernel_size=3,padding=\"same\", input_shape=self.input_shape,\n",
    "        activation=tf.nn.relu)\n",
    "     \n",
    "        self.conv2=nn.Conv2d(filters=32,kernel_size=3, padding=\"same\",stride=2, \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "        self.conv3=nn.Conv2d(filters=64,kernel_size=3,padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "        self.conv4=nn.Conv2d(filters=64,kernel_size=3,padding=\"same\",stride=2,\n",
    "        activation=tf.nn.relu)\n",
    " \n",
    "    def call(self, x):\n",
    "        out=self.conv1(x)\n",
    "        out=self.conv2(out)\n",
    "        out=self.conv3(out)\n",
    "        out=self.conv4(out)\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = t_u.get_loader(train=False,data_dir=config.data_dir,download=config.download\n",
    ",dataset=config.dataset,batch_size=config.load_batch_size,\n",
    "           x_mean=None,x_std=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-016547056823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model, model_shape,model_name=t_u.get_model(config.model_arch, robust_model=config.robust_model, robust_eps=config.robust_eps,\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     download=config.download,dataset=config.dataset, force_train=config.force_train)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't_u' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model, model_shape,model_name=t_u.get_model(config.model_arch, robust_model=config.robust_model, robust_eps=config.robust_eps,\n",
    "    nb_epochs=config.nb_epochs,model_dir=config.model_dir,data_dir=config.data_dir,test_loader=test_loader,\n",
    "    download=config.download,dataset=config.dataset, force_train=config.force_train)\n",
    "\n",
    "input_shape=model_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_correct,label_correct,accuracy=t_u.get_correct_x_y(data_loader=test_loader,model=model)\n",
    "if config.verbose>=2:\n",
    "    print(f\"model accuracy on test batch:{accuracy}\")\n",
    "    config.x_mean=t_u.datasets_means[config.dataset]\n",
    "config.x_std=t_u.datasets_stds[config.dataset]\n",
    "if config.use_attack:\n",
    "\n",
    "    fmodel = fb.TensorFlowModel(model, bounds=(0,1),)\n",
    "    attack=fb.attacks.LinfPGD()\n",
    "    #un-normalize data before performing attack\n",
    "    _, advs, success = attack(fmodel, X_correct[config.input_start:config.input_stop], \n",
    "    label_correct[config.input_start:config.input_stop], epsilons=config.epsilons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Normalize(mean=0, std=1)\n",
       "  (1): CNN_custom(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (activation): ReLU()\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (activation2): ReLU()\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (linear1): Linear(in_features=3136, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "inp_indices=np.arange(start=config.input_start,stop=config.input_stop)\n",
    "normal_dist=torch.distributions.Normal(loc=0, scale=1.)\n",
    "run_nb=0\n",
    "iterator= tqdm(range(config.n_rep))\n",
    "exp_res=[]\n",
    "clip_min=0\n",
    "clip_max=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test EagerPy H-SMC implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in inp_indices:\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        x_0,y_0 = X_correct[l], label_correct[l]\n",
    "\n",
    "   \n",
    "    for idx in range(len(config.epsilons)):\n",
    "        \n",
    "        \n",
    "        epsilon = config.epsilons[idx]\n",
    "        pgd_success= (success[idx][l]).item() if config.use_attack else None \n",
    "        p_l,p_u=None,None\n",
    "        if config.lirpa_bounds:\n",
    "            from stat_reliability_measure.dev.lirpa_utils import get_lirpa_bounds\n",
    "            # Step 2: define perturbation. Here we use a Linf perturbation on input image.\n",
    "            p_l,p_u=get_lirpa_bounds(x_0=x_0,y_0=y_0,model=model,epsilon=epsilon,\n",
    "            num_classes=num_classes,noise_dist=config.noise_dist,a=config.a,device=config.device)\n",
    "            p_l,p_u=p_l.item(),p_u.item()\n",
    "        lirpa_safe=None\n",
    "        if config.lirpa_cert:\n",
    "            assert config.noise_dist.lower()=='uniform',\"Formal certification only makes sense for uniform distributions\"\n",
    "            from stat_reliability_measure.dev.lirpa_utils import get_lirpa_cert\n",
    "            lirpa_safe=get_lirpa_cert(x_0=x_0,y_0=y_0,model=model,epsilon=epsilon,\n",
    "            num_classes=num_classes,device=config.device)\n",
    "\n",
    "        \n",
    "        \n",
    "        if config.gaussian_latent:\n",
    "            gen = lambda N: torch.randn(size=(N,d),device=config.device)\n",
    "        else:\n",
    "            gen= lambda N: (2*torch.rand(size=(N,d), device=device )-1)\n",
    "            \n",
    "        low=torch.maximum(x_0-epsilon, torch.tensor([x_min]).cuda())\n",
    "        low_ep = ep.maximum(ep.astensor(x_0-epsilon), x_min)\n",
    "        high_ep = ep.minimum(ep.astensor(x_0+epsilon), x_max)\n",
    "        high=torch.minimum(x_0+epsilon, torch.tensor([x_max]).cuda())  \n",
    "        V_ = lambda X: t_u.V_pyt(X,x_0=x_0,model=model,low=low,high=high,target_class=y_0,gaussian_latent=config.gaussian_latent)\n",
    "        V_ep2 = lambda X : ep.astensor(V_(X.raw))\n",
    "        V_ep = lambda X: e_u.V_ep(X, model=model,low=low,high=high,target_class=y_0, input_shape = model_shape,gaussian_latent=config.gaussian_latent)\n",
    "        gradV_ = lambda X: t_u.gradV_pyt(X,x_0=x_0,model=model,low=low,high=high, target_class=y_0,gaussian_latent=config.gaussian_latent)\n",
    "        gradV_ep2 = lambda X: ep.astensor(gradV_(X.raw))\n",
    "        gradV_ep = lambda X: e_u.gradV_ep(X,model=model,input_shape=model_shape, low=ep.astensor(low), high = ep.astensor(high), target_class= y_0,  gaussian_latent=config.gaussian_latent)\n",
    "        assert torch.equal(low_ep.raw,low), \"/!\\ lower bounds are not the same\"\n",
    "        assert torch.equal(high_ep.raw,high), \"/!\\ higher bounds are not the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stat_reliability_measure.dev.torch_utils' from '/home/karim-tito/stat_reliability_measure/dev/torch_utils.py'>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(e_u)\n",
    "reload(smc_ep)\n",
    "reload(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/1\n",
      "Starting simulations with model:CNN_custom_mnist img_idx:0,eps=0.3,ess_t:0.875,T:10,alpha:0.2,N:200,L:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:06<?, ?it/s]\n",
      " 85%|████████▍ | 127/150 [45:57<08:19, 21.72s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-2f4f02b92ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                 \u001b[0mv_min_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_min_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                 \u001b[0mtrack_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_dt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madapt_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                                 \u001b[0msig_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGV_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGV_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                                 )\n\u001b[1;32m     37\u001b[0m                                 \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stat_reliability_measure/dev/smc/smc_pyt.py\u001b[0m in \u001b[0;36mSamplerSMC\u001b[0;34m(gen, V, gradV, adapt_func, min_rate, alpha, N, T, L, n_max, max_beta, verbose, device, track_accept, track_beta, return_log_p, gaussian, adapt_dt, track_calls, track_dt, track_H, track_v_means, track_ratios, target_accept, accept_spread, dt_decay, dt_gain, dt_min, dt_max, v_min_opt, lambda_0, debug, kappa_opt, track_ess, M_opt, adapt_step, alpha_p, FT, sig_dt, L_min, only_duplicated, GK_opt, GV_opt, dt_d, skip_mh)\u001b[0m\n\u001b[1;32m    252\u001b[0m                         \u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkappa_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkappa_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_H\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale_M\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale_M\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                         \u001b[0malpha_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msig_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msig_dt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                         gaussian_verlet=GV_opt,dt_min=dt_min,skip_mh=skip_mh)\n\u001b[0m\u001b[1;32m    255\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mFT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0monly_duplicated\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnb_to_renew\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stat_reliability_measure/dev/torch_utils.py\u001b[0m in \u001b[0;36madapt_verlet_mcmc\u001b[0;34m(q, v_q, ind_L, beta, gaussian, V, gradV, T, delta_t, L, kappa_opt, save_H, save_func, device, scale_M, alpha_p, prop_d, FT, dt_max, dt_min, sig_dt, verbose, L_min, gaussian_verlet, skip_mh)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;31m#torch.multinomial(input=)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprod_correl\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0malpha_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mprop_d\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mT_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m         q_trial,p_trial=verlet_kernel1(X=q,gradV=gradV, p_0=p,delta_t=delta_t,beta=beta,L=L,kappa_opt=kappa_opt,\n\u001b[1;32m   1071\u001b[0m         scale_M=scale_M, ind_L=ind_L,GV=gaussian_verlet)\n",
      "\u001b[0;32m~/stat_reliability_measure/dev/torch_utils.py\u001b[0m in \u001b[0;36mverlet_kernel1\u001b[0;34m(X, gradV, delta_t, beta, L, ind_L, p_0, lambda_, gaussian, kappa_opt, scale_M, GV)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m#updating momentum again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mGV\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mp_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mp_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mp_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mq_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m#II. Optional smoothing of momentum memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-143-2b5b50878482>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mV_ep2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mV_ep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0me_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV_ep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgaussian_latent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mgradV_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradV_pyt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgaussian_latent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mgradV_ep2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradV_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mgradV_ep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0me_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradV_ep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgaussian_latent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stat_reliability_measure/dev/torch_utils.py\u001b[0m in \u001b[0;36mgradV_pyt\u001b[0;34m(x_, x_0, model, target_class, low, high, gaussian_latent, reshape, input_shape, gaussian_prior)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mx_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mx_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_x_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_V_grad_pyt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m     \u001b[0mgrad_u\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_x_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgaussian_prior\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_x_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgaussian_latent\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgaussian_prior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stat_reliability_measure/dev/torch_utils.py\u001b[0m in \u001b[0;36mcompute_V_grad_pyt\u001b[0;34m(model, input_, target_class, L)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0minput_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    234\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "for ess_t in config.e_range:\n",
    "            if config.adapt_func.lower()=='ess':\n",
    "                adapt_func = lambda beta,v : smc_pyt.nextBetaESS(beta_old=beta,v=v,ess_alpha=ess_t,max_beta=1e6)\n",
    "            for T in config.T_range:\n",
    "                for L in config.L_range:\n",
    "                    for alpha in config.alpha_range:       \n",
    "                        for N in config.N_range:\n",
    "                            loc_time= datetime.today().isoformat().split('.')[0]\n",
    "                            log_name=method_name+f'_N_{N}_T_{T}_L_{L}_a_{float_to_file_float(alpha)}_ess_{float_to_file_float(ess_t)}'+'_'+loc_time.split('_')[0]\n",
    "                            log_path=os.path.join(exp_log_path,log_name)\n",
    "                            if os.path.exists(log_path):\n",
    "                                log_path = log_path + '_'+str(np.random.randint(low=0,high =10))\n",
    "                            \n",
    "                            \n",
    "                            os.mkdir(path=log_path)\n",
    "                            run_nb+=1\n",
    "                            print(f'Run {run_nb}/{nb_runs}')\n",
    "                            times=[]\n",
    "                            ests = []\n",
    "                            calls=[]\n",
    "                            finished_flags=[]\n",
    "                            iterator= tqdm(range(config.n_rep)) if config.tqdm_opt else range(config.n_rep)\n",
    "                            print(f\"Starting simulations with model:{model_name} img_idx:{l},eps={epsilon},ess_t:{ess_t},T:{T},alpha:{alpha},N:{N},L:{L}\")\n",
    "                            for i in iterator:\n",
    "                                t=time()\n",
    "                                p_est,res_dict,=smc_pyt.SamplerSMC(gen=gen,V= V_,gradV=gradV_,adapt_func=adapt_func,min_rate=config.min_rate,N=N,T=T,L=L,\n",
    "                                alpha=alpha,n_max=config.n_max,L_min=config.L_min,\n",
    "                                verbose=config.verbose, track_accept=config.track_accept,track_beta=config.track_beta,track_v_means=config.track_v_means,\n",
    "                                track_ratios=config.track_ratios,track_ess=config.track_ess,kappa_opt=config.kappa_opt\n",
    "                                ,gaussian =True,accept_spread=config.accept_spread, \n",
    "                                adapt_dt=config.adapt_dt, dt_decay=config.dt_decay,\n",
    "                                dt_gain=config.dt_gain,dt_min=config.dt_min,dt_max=config.dt_max,\n",
    "                                v_min_opt=config.v_min_opt,\n",
    "                                track_dt=config.track_dt,M_opt=config.M_opt,adapt_step=config.adapt_step,FT=config.FT,\n",
    "                                sig_dt=config.sig_dt, skip_mh=config.skip_mh,GV_opt=config.GV_opt\n",
    "                                )\n",
    "                                t1=time()-t\n",
    "                                if config.verbose>=2:\n",
    "                                    print(p_est)\n",
    "                                #finish_flag=res_dict['finished']\n",
    "                                \n",
    "                                if config.track_accept:\n",
    "                                    accept_rates_mcmc=res_dict['accept_rates_mcmc']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'accept_rates_mcmc_{i}.txt')\n",
    "                                    ,X=accept_rates_mcmc,)\n",
    "                                    x_T=np.arange(len(accept_rates_mcmc))\n",
    "                                    plt.plot(x_T,accept_rates_mcmc)\n",
    "                                    plt.savefig(os.path.join(log_path,f'accept_rates_mcmc_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                    \n",
    "\n",
    "                                if config.track_dt:\n",
    "                                    dts=res_dict['dts']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'dts_{i}.txt')\n",
    "                                    ,X=dts)\n",
    "                                    x_T=np.arange(len(dts))\n",
    "                                    plt.plot(x_T,dts)\n",
    "                                    plt.savefig(os.path.join(log_path,f'dts_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                \n",
    "                                \n",
    "                                times.append(t1)\n",
    "                                ests.append(p_est)\n",
    "                                calls.append(res_dict['calls'])\n",
    "                            times=np.array(times)\n",
    "                            ests = np.array(ests)\n",
    "                            calls=np.array(calls)\n",
    "                        \n",
    "                            mean_calls=calls.mean()\n",
    "                            std_est=ests.std()\n",
    "                            mean_est=ests.mean()\n",
    "                            std_rel=std_est/mean_est\n",
    "                            std_rel_adj=std_rel*mean_calls\n",
    "                            print(f\"Native PyTorch peformance\")\n",
    "                            print(f\"mean est:{ests.mean()}, std est:{ests.std()}\")\n",
    "                            print(f\"mean calls:{calls.mean()}\")\n",
    "                            print(f\"std. rel.:{std_rel}\")\n",
    "                            print(f\"std. rel. adj.:{std_rel*mean_calls}\")\n",
    "                            print(f\"mean time:{times.mean()}, std. time:{times.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 21/1\n",
      "Starting simulations with model:CNN_custom_mnist img_idx:0,eps=0.3,ess_t:0.875,T:5,alpha:0.2,N:100,L:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:32<00:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean est:2.1818558337827199e-07, std est:6.307335827283335e-08\n",
      "mean calls:57303.9544\n",
      "std. rel.:0.2890812366987695\n",
      "std. rel. adj.:16565.498005681897\n",
      "mean time:3.1519405126571653, std. time:0.41938986478090917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ess_t in config.e_range:\n",
    "            if config.adapt_func.lower()=='ess':\n",
    "                adapt_func = lambda beta,v : smc_ep.nextBetaESS(beta_old=beta,v=v,ess_alpha=ess_t,max_beta=1e6)\n",
    "            for T in config.T_range:\n",
    "                for L in config.L_range:\n",
    "                    for alpha in config.alpha_range:       \n",
    "                        for N in config.N_range:\n",
    "                            loc_time= datetime.today().isoformat().split('.')[0]\n",
    "                            log_name=method_name+f'_N_{N}_T_{T}_L_{L}_a_{float_to_file_float(alpha)}_ess_{float_to_file_float(ess_t)}'+'_'+loc_time.split('_')[0]\n",
    "                            log_path=os.path.join(exp_log_path,log_name)\n",
    "                            if os.path.exists(log_path):\n",
    "                                log_path = log_path + '_'+str(np.random.randint(low=0,high =10))\n",
    "                            \n",
    "                            \n",
    "                            os.mkdir(path=log_path)\n",
    "                            run_nb+=1\n",
    "                            print(f'Run {run_nb}/{nb_runs}')\n",
    "                            times=[]\n",
    "                            ests = []\n",
    "                            calls=[]\n",
    "                            finished_flags=[]\n",
    "                            iterator= tqdm(range(config.n_rep)) if config.tqdm_opt else range(config.n_rep)\n",
    "                            print(f\"Starting simulations with model:{model_name} img_idx:{l},eps={epsilon},ess_t:{ess_t},T:{T},alpha:{alpha},N:{N},L:{L}\")\n",
    "                            for i in iterator:\n",
    "                                t=time()\n",
    "                                p_est,res_dict,=smc_ep.SamplerSMC(gen=gen,V= V_ep2,gradV=gradV_ep,adapt_func=adapt_func,min_rate=config.min_rate,N=N,T=T,L=L,\n",
    "                                alpha=alpha,n_max=config.n_max,L_min=config.L_min,\n",
    "                                verbose=config.verbose, track_accept=config.track_accept,track_beta=config.track_beta,track_v_means=config.track_v_means,\n",
    "                                track_ratios=config.track_ratios,track_ess=config.track_ess,kappa_opt=config.kappa_opt\n",
    "                                ,gaussian =True,accept_spread=config.accept_spread, \n",
    "                                adapt_dt=config.adapt_dt, dt_decay=config.dt_decay,\n",
    "                                dt_gain=config.dt_gain,dt_min=config.dt_min,dt_max=config.dt_max,\n",
    "                                v_min_opt=config.v_min_opt,\n",
    "                                track_dt=config.track_dt,M_opt=config.M_opt,adapt_step=config.adapt_step,FT=config.FT,\n",
    "                                sig_dt=config.sig_dt, skip_mh=config.skip_mh,GV_opt=config.GV_opt\n",
    "                                )\n",
    "                                t1=time()-t\n",
    "\n",
    "                                if config.verbose>=2:\n",
    "                                    print(p_est)\n",
    "                                #finish_flag=res_dict['finished']\n",
    "                                \n",
    "                                if config.track_accept:\n",
    "                                    accept_rates_mcmc=res_dict['accept_rates_mcmc']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'accept_rates_mcmc_{i}.txt')\n",
    "                                    ,X=accept_rates_mcmc,)\n",
    "                                    x_T=np.arange(len(accept_rates_mcmc))\n",
    "                                    plt.plot(x_T,accept_rates_mcmc)\n",
    "                                    plt.savefig(os.path.join(log_path,f'accept_rates_mcmc_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                    \n",
    "\n",
    "                                if config.track_dt:\n",
    "                                    dts=res_dict['dts']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'dts_{i}.txt')\n",
    "                                    ,X=dts)\n",
    "                                    x_T=np.arange(len(dts))\n",
    "                                    plt.plot(x_T,dts)\n",
    "                                    plt.savefig(os.path.join(log_path,f'dts_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                \n",
    "                                \n",
    "                                times.append(t1)\n",
    "                                ests.append(p_est)\n",
    "                                calls.append(res_dict['calls'])\n",
    "                            times=np.array(times)\n",
    "                            ests = np.array(ests)\n",
    "                            calls=np.array(calls)\n",
    "                        \n",
    "                            mean_calls=calls.mean()\n",
    "                            std_est=ests.std()\n",
    "                            mean_est=ests.mean()\n",
    "                            std_rel=std_est/mean_est\n",
    "                            std_rel_adj=std_rel*mean_calls\n",
    "                            print(f\"EagerPy implementation with PyTorch function feed\")\n",
    "                            print(f\"mean est:{ests.mean()}, std est:{ests.std()}\")\n",
    "                            print(f\"mean calls:{calls.mean()}\")\n",
    "                            print(f\"std. rel.:{std_rel}\")\n",
    "                            print(f\"std. rel. adj.:{std_rel*mean_calls}\")\n",
    "                            print(f\"mean time:{times.mean()}, std. time:{times.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 17/1\n",
      "Starting simulations with model:CNN_custom_mnist img_idx:0,eps=0.3,ess_t:0.875,T:5,alpha:0.2,N:100,L:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean est:1.8418282223819916e-07, std est:4.035993939759841e-08\n",
      "mean calls:59915.52\n",
      "std. rel.:0.21912976957971622\n",
      "std. rel. adj.:13129.274091848878\n",
      "mean time:2.6192834615707397, std. time:0.16873597262760243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ess_t in config.e_range:\n",
    "            if config.adapt_func.lower()=='ess':\n",
    "                adapt_func = lambda beta,v : smc_ep.nextBetaESS(beta_old=beta,v=v,ess_alpha=ess_t,max_beta=1e6)\n",
    "            for T in config.T_range:\n",
    "                for L in config.L_range:\n",
    "                    for alpha in config.alpha_range:       \n",
    "                        for N in config.N_range:\n",
    "                            loc_time= datetime.today().isoformat().split('.')[0]\n",
    "                            log_name=method_name+f'_N_{N}_T_{T}_L_{L}_a_{float_to_file_float(alpha)}_ess_{float_to_file_float(ess_t)}'+'_'+loc_time.split('_')[0]\n",
    "                            log_path=os.path.join(exp_log_path,log_name)\n",
    "                            if os.path.exists(log_path):\n",
    "                                log_path = log_path + '_'+str(np.random.randint(low=0,high =10))\n",
    "                            \n",
    "                            \n",
    "                            os.mkdir(path=log_path)\n",
    "                            run_nb+=1\n",
    "                            print(f'Run {run_nb}/{nb_runs}')\n",
    "                            times=[]\n",
    "                            ests = []\n",
    "                            calls=[]\n",
    "                            finished_flags=[]\n",
    "                            iterator= tqdm(range(config.n_rep)) if config.tqdm_opt else range(config.n_rep)\n",
    "                            print(f\"Starting simulations with model:{model_name} img_idx:{l},eps={epsilon},ess_t:{ess_t},T:{T},alpha:{alpha},N:{N},L:{L}\")\n",
    "                            for i in iterator:\n",
    "                                t=time()\n",
    "                                p_est,res_dict,=smc_ep.SamplerSMC(gen=gen,V= V_ep,gradV=gradV_ep2,adapt_func=adapt_func,min_rate=config.min_rate,N=N,T=T,L=L,\n",
    "                                alpha=alpha,n_max=config.n_max,L_min=config.L_min,\n",
    "                                verbose=config.verbose, track_accept=config.track_accept,track_beta=config.track_beta,track_v_means=config.track_v_means,\n",
    "                                track_ratios=config.track_ratios,track_ess=config.track_ess,kappa_opt=config.kappa_opt\n",
    "                                ,gaussian =True,accept_spread=config.accept_spread, \n",
    "                                adapt_dt=config.adapt_dt, dt_decay=config.dt_decay,\n",
    "                                dt_gain=config.dt_gain,dt_min=config.dt_min,dt_max=config.dt_max,\n",
    "                                v_min_opt=config.v_min_opt,\n",
    "                                track_dt=config.track_dt,M_opt=config.M_opt,adapt_step=config.adapt_step,FT=config.FT,\n",
    "                                sig_dt=config.sig_dt, skip_mh=config.skip_mh,GV_opt=config.GV_opt\n",
    "                                )\n",
    "                                t1=time()-t\n",
    "\n",
    "                                if config.verbose>=2:\n",
    "                                    print(p_est)\n",
    "                                #finish_flag=res_dict['finished']\n",
    "                                \n",
    "                                if config.track_accept:\n",
    "                                    accept_rates_mcmc=res_dict['accept_rates_mcmc']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'accept_rates_mcmc_{i}.txt')\n",
    "                                    ,X=accept_rates_mcmc,)\n",
    "                                    x_T=np.arange(len(accept_rates_mcmc))\n",
    "                                    plt.plot(x_T,accept_rates_mcmc)\n",
    "                                    plt.savefig(os.path.join(log_path,f'accept_rates_mcmc_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                    \n",
    "\n",
    "                                if config.track_dt:\n",
    "                                    dts=res_dict['dts']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'dts_{i}.txt')\n",
    "                                    ,X=dts)\n",
    "                                    x_T=np.arange(len(dts))\n",
    "                                    plt.plot(x_T,dts)\n",
    "                                    plt.savefig(os.path.join(log_path,f'dts_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                \n",
    "                                \n",
    "                                times.append(t1)\n",
    "                                ests.append(p_est)\n",
    "                                calls.append(res_dict['calls'])\n",
    "                            times=np.array(times)\n",
    "                            ests = np.array(ests)\n",
    "                            calls=np.array(calls)\n",
    "                        \n",
    "                            mean_calls=calls.mean()\n",
    "                            std_est=ests.std()\n",
    "                            mean_est=ests.mean()\n",
    "                            std_rel=std_est/mean_est\n",
    "                            std_rel_adj=std_rel*mean_calls\n",
    "                            print(f\"Full EagerPy implementation\")\n",
    "                            print(f\"mean est:{ests.mean()}, std est:{ests.std()}\")\n",
    "                            print(f\"mean calls:{calls.mean()}\")\n",
    "                            print(f\"std. rel.:{std_rel}\")\n",
    "                            print(f\"std. rel. adj.:{std_rel*mean_calls}\")\n",
    "                            print(f\"mean time:{times.mean()}, std. time:{times.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('deep_learning_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc988435c4b631969eb5fce6943044c00d5bb2dcddaf96f4811676fc0db79e94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

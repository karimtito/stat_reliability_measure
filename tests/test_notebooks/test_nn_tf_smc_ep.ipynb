{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing EagerPy implementation of H-SMC on MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stat\n",
    "import numpy as np\n",
    "import eagerpy as ep\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "import GPUtil\n",
    "import foolbox as fb\n",
    "import cpuinfo\n",
    "import pandas as pd\n",
    "from stat_reliability_measure.dev.utils import str2bool,str2floatList,str2intList,float_to_file_float,dichotomic_search,datasets_dims,datasets_num_c\n",
    "from scipy.special import betainc\n",
    "from importlib import reload\n",
    "from stat_reliability_measure.home import ROOT_DIR\n",
    "from stat_reliability_measure.dev.tf_utils import dic_in_shape_tf\n",
    "from stat_reliability_measure.dev.tf_arch import CNN_custom_tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stat_reliability_measure.dev.smc.smc_ep as smc_ep\n",
    "import stat_reliability_measure.dev.ep_utils as e_u\n",
    "import stat_reliability_measure.dev.smc.smc_pyt as smc_pyt\n",
    "import stat_reliability_measure.dev.tf_utils as tf_u\n",
    "import stat_reliability_measure.dev.utils as u\n",
    "import stat_reliability_measure.dev.tf_arch as t_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stat_reliability_measure.dev.tf_arch' from '/home/karim-tito/stat_reliability_measure/dev/tf_arch.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(smc_ep)\n",
    "reload(tf_u)\n",
    "reload(e_u)\n",
    "reload(u)\n",
    "reload(t_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name=\"smc_ep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    dataset='mnist'\n",
    "    N=20\n",
    "    N_range=[]\n",
    "    T=10\n",
    "    T_range=[]\n",
    "    L=5\n",
    "    L_range=[]\n",
    "    min_rate=0.2\n",
    "    \n",
    "    alpha=0.2\n",
    "    alpha_range=[]\n",
    "    ess_alpha=0.875\n",
    "    e_range=[]\n",
    "   \n",
    "    n_rep=150\n",
    "    \n",
    "    save_config=False \n",
    "    print_config=True\n",
    "    \n",
    "    x_min=0\n",
    "    x_max=1\n",
    "    x_mean=0\n",
    "    x_std=1\n",
    "\n",
    "    epsilons = None\n",
    "    eps_max=0.3\n",
    "    eps_min=0.2\n",
    "    eps_num=5\n",
    "    model_arch='CNN_custom'\n",
    "    model_path=None\n",
    "    export_to_onnx=False\n",
    "    use_attack=False\n",
    "    attack='PGD'\n",
    "    lirpa_bounds=False\n",
    "    download=True\n",
    "    train_model=False\n",
    "    \n",
    "    \n",
    "    noise_dist='uniform'\n",
    "    d=None\n",
    "    verbose=0\n",
    "    log_dir=None\n",
    "    aggr_res_path = None\n",
    "    update_aggr_res=False\n",
    "    sigma=1\n",
    "    v1_kernel=True\n",
    "    torch_seed=None\n",
    "    gpu_name=None\n",
    "    cpu_name=None\n",
    "    cores_number=None\n",
    "    track_gpu=False\n",
    "    track_cpu=False\n",
    "    \n",
    "    n_max=10000 \n",
    "    allow_multi_gpu=True\n",
    "    tqdm_opt=True\n",
    "    allow_zero_est=True\n",
    "    track_accept=True\n",
    "    track_calls=False\n",
    "    mh_opt=False\n",
    "    adapt_dt=False\n",
    "    adapt_dt_mcmc=False\n",
    "    target_accept=0.574\n",
    "    accept_spread=0.1\n",
    "    dt_decay=0.999\n",
    "    dt_gain=None\n",
    "    dt_min=1e-5\n",
    "    dt_max=0.7\n",
    "    v_min_opt=True\n",
    "    ess_opt=False\n",
    "    only_duplicated=True\n",
    "    np_seed=None\n",
    "    lambda_0=0.5\n",
    "    test2=False\n",
    "\n",
    "    s_opt=False\n",
    "    s=1\n",
    "    clip_s=True\n",
    "    s_min=1e-3\n",
    "    s_max=3\n",
    "    s_decay=0.95\n",
    "    s_gain=1.0001\n",
    "\n",
    "    track_dt=False\n",
    "    mult_last=True\n",
    "    linear=True\n",
    "\n",
    "    track_ess=True\n",
    "    track_beta=True\n",
    "    track_dt=True\n",
    "    track_v_means=True\n",
    "    track_ratios=False\n",
    "\n",
    "    kappa_opt=True\n",
    "\n",
    "    adapt_func='ESS'\n",
    "    M_opt = False\n",
    "    adapt_step=True\n",
    "    FT=True\n",
    "    sig_dt=0.02\n",
    "\n",
    "    batch_opt=True\n",
    "    track_finish=False\n",
    "    lirpa_cert=False\n",
    "    robust_model=False\n",
    "    robust_eps=0.1\n",
    "    load_batch_size=100 \n",
    "    nb_epochs= 10\n",
    "    adversarial_every=1\n",
    "    data_dir=ROOT_DIR+\"/data\"\n",
    "    p_ref_compute=False\n",
    "    input_start=0\n",
    "    input_stop=None\n",
    "\n",
    "    gaussian_latent=True\n",
    "\n",
    "    model_dir=None \n",
    "    L_min=1\n",
    "    GK_opt=False\n",
    "    GV_opt=False\n",
    "    g_target=0.8\n",
    "    skip_mh=False\n",
    "    force_train=False\n",
    "    killing=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reliability experiments on architecture CNN_custom trained on mnist.\n",
      "Testing uniform noise pertubatin with epsilon in [0.2        0.22133638 0.24494897 0.2710806  0.3       ]\n"
     ]
    }
   ],
   "source": [
    "if config.model_dir is None:\n",
    "    config.model_dir=os.path.join(ROOT_DIR+\"/models/\",config.dataset)\n",
    "    if not os.path.exists(config.model_dir):\n",
    "        os.mkdir(config.model_dir)\n",
    "\n",
    "config.d = u.datasets_dims[config.dataset]\n",
    "color_dataset=config.dataset in ('cifar10','cifar100','imagenet') \n",
    "#assert config.adapt_func.lower() in smc_pyt.supported_beta_adapt.keys(),f\"select adaptive function in {smc_pyt.supported_beta_adapt.keys}\"\n",
    "#adapt_func=smc_pyt.supported_beta_adapt[config.adapt_func.lower()]\n",
    "\n",
    "if config.adapt_func.lower()=='simp_ess':\n",
    "    adapt_func = lambda beta,v : smc_pyt.nextBetaSimpESS(beta_old=beta,v=v,lambda_0=config.lambda_0,max_beta=1e6)\n",
    "elif config.adapt_func.lower()=='simp':\n",
    "    adapt_func = lambda beta,v: smc_pyt.SimpAdaptBetaPyt(beta,v,config.g_target,v_min_opt=config.v_min_opt)\n",
    "prblm_str=config.dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if len(config.e_range)==0:\n",
    "    config.e_range= [config.ess_alpha]\n",
    "\n",
    "if config.input_stop is None:\n",
    "    config.input_stop=config.input_start+1\n",
    "else:\n",
    "    assert config.input_start<config.input_stop,\"/!\\ input start must be strictly lower than input stop\"\n",
    "if len(config.N_range)==0:\n",
    "    config.N_range= [config.N]\n",
    "\n",
    "if config.noise_dist is not None:\n",
    "    config.noise_dist=config.noise_dist.lower()\n",
    "\n",
    "if config.noise_dist not in ['uniform','gaussian']:\n",
    "    raise NotImplementedError(\"Only uniform and Gaussian distributions are implemented.\")\n",
    "\n",
    "if len(config.T_range)==0:\n",
    "    config.T_range= [config.T]\n",
    "\n",
    "if len(config.L_range)==0:\n",
    "    config.L_range= [config.L]\n",
    "if len(config.alpha_range)==0:\n",
    "    config.alpha_range= [config.alpha]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if config.np_seed is None:\n",
    "    config.np_seed=int(time())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if config.track_gpu:\n",
    "    gpus=GPUtil.getGPUs()\n",
    "    if len(gpus)>1:\n",
    "        print(\"Multi gpus detected, only the first GPU will be tracked.\")\n",
    "    config.gpu_name=gpus[0].name\n",
    "\n",
    "if config.track_cpu:\n",
    "    config.cpu_name=cpuinfo.get_cpu_info()[[key for key in cpuinfo.get_cpu_info().keys() if 'brand' in key][0]]\n",
    "    config.cores_number=os.cpu_count()\n",
    "\n",
    "\n",
    "\n",
    "d=config.d\n",
    "#epsilon=config.epsilon\n",
    "\n",
    "if config.log_dir is None:\n",
    "    config.log_dir=os.path.join(ROOT_DIR+'/logs',config.dataset+'_tests')\n",
    "if not os.path.exists(ROOT_DIR+'/logs'):\n",
    "    os.mkdir(ROOT_DIR+'/logs')  \n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.mkdir(config.log_dir)\n",
    "\n",
    "results_path=os.path.join(config.log_dir,'results.csv')\n",
    "if os.path.exists(results_path):\n",
    "    results_g=pd.read_csv(results_path)\n",
    "else:\n",
    "    results_g=pd.DataFrame(columns=['mean_est','mean_time','mean_err','stdtime','std_est','T','N','rho','alpha','n_rep','min_rate','method'])\n",
    "    results_g.to_csv(results_path,index=False)\n",
    "raw_logs = os.path.join(config.log_dir,'raw_logs/')\n",
    "if not os.path.exists(raw_logs):\n",
    "    os.mkdir(raw_logs)\n",
    "raw_logs_path=os.path.join(config.log_dir,'raw_logs/'+method_name)\n",
    "if not os.path.exists(raw_logs_path):\n",
    "    os.mkdir(raw_logs_path)\n",
    "\n",
    "loc_time= datetime.today().isoformat().split('.')[0].replace('-','_').replace(':','_')
    log_name=method_name+'_'+'_'+loc_time\n",
    "log_name=method_name+'_'+'_'+loc_time\n",
    "exp_log_path=os.path.join(raw_logs_path,log_name)\n",
    "if os.path.exists(path=exp_log_path):\n",
    "    exp_log_path = exp_log_path+'_'+str(np.random.randint(low=0,high=9))\n",
    "os.mkdir(path=exp_log_path)\n",
    "\n",
    "# if config.aggr_res_path is None:\n",
    "#     aggr_res_path=os.path.join(config.log_dir,'agg_res.csv')\n",
    "# else:\n",
    "#     aggr_res_path=config.aggr_res_path\n",
    "\n",
    "if config.dt_gain is None:\n",
    "    config.dt_gain=1/config.dt_decay\n",
    "\n",
    "\n",
    "\n",
    "if config.epsilons is None:\n",
    "    log_min,log_max=np.log(config.eps_min),np.log(config.eps_max)\n",
    "    log_line=np.linspace(start=log_min,stop=log_max,num=config.eps_num)\n",
    "    config.epsilons=np.exp(log_line)\n",
    "\n",
    "param_ranges = [config.N_range,config.T_range,config.L_range,config.e_range,config.alpha_range]\n",
    "param_lens=np.array([len(l) for l in param_ranges])\n",
    "nb_runs= np.prod(param_lens)\n",
    "\n",
    "mh_str=\"adjusted\" \n",
    "method=method_name\n",
    "save_every = 1\n",
    "x_min=0\n",
    "x_max=1\n",
    "#adapt_func= smc_pyt.ESSAdaptBetaPyt if config.ess_opt else smc_pyt.SimpAdaptBetaPyt\n",
    "num_classes=u.datasets_num_c[config.dataset.lower()]\n",
    "print(f\"Running reliability experiments on architecture {config.model_arch} trained on {config.dataset}.\")\n",
    "print(f\"Testing uniform noise pertubatin with epsilon in {config.epsilons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config.model_arch\n",
    "if model_name.lower()=='cnn_custom':\n",
    "    model = t_a.CNN_custom_tf()\n",
    "else:\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 6s 8ms/step - loss: 0.4588 - sparse_categorical_accuracy: 0.8713 - val_loss: 0.0552 - val_sparse_categorical_accuracy: 0.9835\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9839 - val_loss: 0.0412 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0344 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.0391 - val_sparse_categorical_accuracy: 0.9876\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0215 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0341 - val_sparse_categorical_accuracy: 0.9907\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0357 - val_sparse_categorical_accuracy: 0.9893\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0322 - val_sparse_categorical_accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "history =model.fit(\n",
    "    ds_train, \n",
    "    epochs=6,\n",
    "    validation_data=ds_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_custom_tf\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            multiple                  36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  313700    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1010      \n",
      "=================================================================\n",
      "Total params: 379,702\n",
      "Trainable params: 379,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "for X_test,y_test in ds_test.__iter__():\n",
    "    print(X_test.shape)\n",
    "    break\n",
    "log_pred = model.predict(X_test)\n",
    "y_pred = tf.argmax(log_pred,axis=1)\n",
    "correct = tf.equal(y_pred,y_test)\n",
    "X_correct, y_correct= X_test[correct], y_test[correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "inp_indices=np.arange(start=config.input_start,stop=config.input_stop)\n",
    "normal_dist=tfp.distributions.Normal(loc=0, scale=1.)\n",
    "run_nb=0\n",
    "iterator= tqdm(range(config.n_rep))\n",
    "exp_res=[]\n",
    "clip_min=0\n",
    "clip_max=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test EagerPy implementation on TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in inp_indices:\n",
    "    x_clean,y_clean = X_correct[l],tf.cast(y_correct[l],dtype=tf.int32) \n",
    "\n",
    "   \n",
    "    for idx in range(len(config.epsilons)):\n",
    "        \n",
    "        \n",
    "        epsilon = config.epsilons[idx]\n",
    "        p_l,p_u=None,None\n",
    "        if config.lirpa_bounds:\n",
    "            from stat_reliability_measure.dev.lirpa_utils import get_lirpa_bounds\n",
    "            # Step 2: define perturbation. Here we use a Linf perturbation on input image.\n",
    "            p_l,p_u=get_lirpa_bounds(x_clean=x_clean,y_clean=y_clean,model=model,epsilon=epsilon,\n",
    "            num_classes=num_classes,noise_dist=config.noise_dist,a=config.a,device=config.device)\n",
    "            p_l,p_u=p_l.item(),p_u.item()\n",
    "        lirpa_safe=None\n",
    "        if config.lirpa_cert:\n",
    "            assert config.noise_dist.lower()=='uniform',\"Formal certification only makes sense for uniform distributions\"\n",
    "            from stat_reliability_measure.dev.lirpa_utils import get_lirpa_cert\n",
    "            lirpa_safe=get_lirpa_cert(x_clean=x_clean,y_clean=y_clean,model=model,epsilon=epsilon,\n",
    "            num_classes=num_classes,device=config.device)\n",
    "\n",
    "        \n",
    "        \n",
    "        if config.gaussian_latent:\n",
    "            gen = lambda N: tf.random.normal(shape=(N,d))\n",
    "        else:\n",
    "            gen= lambda N: (2*tf.random.uniform(shape=(N,d))-1)\n",
    "            \n",
    "        low=tf.maximum(x_clean-epsilon, tf.constant([float(x_min)]))\n",
    "        low_ep = ep.maximum(ep.astensor(x_clean-epsilon), x_min)\n",
    "        high_ep = ep.minimum(ep.astensor(x_clean+epsilon), x_max)\n",
    "        high=tf.minimum(x_clean+epsilon, tf.constant([float(x_max)]))  \n",
    "   \n",
    "        V_ep = lambda X: e_u.V_ep(X, model=model,low=ep.astensor(low), high = ep.astensor(high),target_class=y_clean, input_shape = model.model_shape,gaussian_latent=config.gaussian_latent)\n",
    "    \n",
    "        gradV_ep = lambda X: e_u.gradV_ep(X,model=model,input_shape=model.model_shape, low=ep.astensor(low), high = ep.astensor(high), target_class= y_clean,  gaussian_latent=config.gaussian_latent)\n",
    "        assert tf.math.reduce_all(low_ep.raw==low), \"/!\\ lower bounds are not the same\"\n",
    "        assert tf.math.reduce_all(high_ep.raw==high), \"/!\\ higher bounds are not the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_correct,y_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/1\n",
      "Starting {method} simulations with model:CNN_custom img_idx:0,eps=0.3,ess_t:0.875,T:10,alpha:0.2,N:20,L:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/150 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "x and y must have the same dtype, got tf.float32 != tf.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0mr_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__r%s__\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1508\u001b[0m           \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m           (dtype.name, value.dtype.name, value))\n\u001b[0m\u001b[1;32m   1510\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor: shape=(20,), dtype=float32, numpy=\narray([2571.7075 , 3076.8975 , 1374.7301 , 3325.9436 ,  487.72284,\n       2925.7969 ,  430.05646, 3260.8657 , 3526.5054 , 2754.7207 ,\n        424.9991 , 1474.1057 , 2254.6057 ,  492.1201 , 3031.7917 ,\n       1692.1736 , 3119.798  , 1510.3445 ,  447.9555 , 1637.5273 ],\n      dtype=float32)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f3efbdd53d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                 \u001b[0mv_min_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_min_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                 \u001b[0mtrack_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_dt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madapt_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                                 \u001b[0msig_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGV_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGV_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                                 )\n\u001b[1;32m     37\u001b[0m                                 \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stat_reliability_measure/dev/smc/smc_ep.py\u001b[0m in \u001b[0;36mSamplerSMC\u001b[0;34m(gen, V, gradV, adapt_func, min_rate, alpha, N, T, L, n_max, max_beta, verbose, device, track_accept, track_beta, return_log_p, gaussian, adapt_dt, track_calls, track_dt, track_H, track_v_means, track_ratios, target_accept, accept_spread, dt_decay, dt_gain, dt_min, dt_max, v_min_opt, lambda_0, debug, kappa_opt, track_ess, M_opt, adapt_step, alpha_p, FT, sig_dt, L_min, only_duplicated, GK_opt, GV_opt, dt_d, skip_mh)\u001b[0m\n\u001b[1;32m    222\u001b[0m                         \u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkappa_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkappa_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_H\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale_M\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale_M\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                         \u001b[0malpha_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msig_dt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msig_dt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                         gaussian_verlet=GV_opt,dt_min=dt_min,skip_mh=skip_mh)\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mFT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0monly_duplicated\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnb_to_renew\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stat_reliability_measure/dev/ep_utils.py\u001b[0m in \u001b[0;36madapt_verlet_mcmc_ep\u001b[0;34m(q, v_q, ind_L, beta, gaussian, V, gradV, T, delta_t, L, kappa_opt, save_H, save_func, device, scale_M, alpha_p, prop_d, FT, dt_max, dt_min, sig_dt, verbose, L_min, gaussian_verlet, skip_mh)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mFT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mexp_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_H\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mm_distances\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmaha_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mlambda_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm_distances\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexp_weight\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm_distances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlambda_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/eagerpy/tensor/base.py\u001b[0m in \u001b[0;36m__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__truediv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorOrScalar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__truediv__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrap1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m   \"\"\"\n\u001b[0;32m-> 1336\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep_learning_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m       raise TypeError(\"x and y must have the same dtype, got %r != %r\" %\n\u001b[0;32m-> 1267\u001b[0;31m                       (x_dtype, y_dtype))\n\u001b[0m\u001b[1;32m   1268\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TRUEDIV_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_dtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: x and y must have the same dtype, got tf.float32 != tf.float64"
     ]
    }
   ],
   "source": [
    "for ess_t in config.e_range:\n",
    "            if config.adapt_func.lower()=='ess':\n",
    "                adapt_func = lambda beta,v : smc_ep.nextBetaESS(beta_old=beta,v=v,ess_alpha=ess_t,max_beta=1e6)\n",
    "            for T in config.T_range:\n",
    "                for L in config.L_range:\n",
    "                    for alpha in config.alpha_range:       \n",
    "                        for N in config.N_range:\n",
    "                            loc_time= datetime.today().isoformat().split('.')[0].replace('-','_').replace(':','_')
    log_name=method_name+'_'+'_'+loc_time\n",
    "                            log_name=method_name+f'_N_{N}_T_{T}_L_{L}_a_{float_to_file_float(alpha)}_ess_{float_to_file_float(ess_t)}'+'_'+loc_time.split('_')[0]\n",
    "                            log_path=os.path.join(exp_log_path,log_name)\n",
    "                            if os.path.exists(log_path):\n",
    "                                log_path = log_path + '_'+str(np.random.randint(low=0,high =10))\n",
    "                            \n",
    "                            \n",
    "                            os.mkdir(path=log_path)\n",
    "                            run_nb+=1\n",
    "                            print(f'Run {run_nb}/{nb_runs}')\n",
    "                            times=[]\n",
    "                            ests = []\n",
    "                            calls=[]\n",
    "                            finished_flags=[]\n",
    "                            iterator= tqdm(range(config.n_rep)) if config.tqdm_opt else range(config.n_rep)\n",
    "                            print(f\"Starting {method} simulations with model:{model_name} img_idx:{l},eps={epsilon},ess_t:{ess_t},T:{T},alpha:{alpha},N:{N},L:{L}\")\n",
    "                            for i in iterator:\n",
    "                                t=time()\n",
    "                                p_est,res_dict,=smc_ep.SamplerSMC(gen=gen,V= V_ep,gradV=gradV_ep,adapt_func=adapt_func,min_rate=config.min_rate,N=N,T=T,L=L,\n",
    "                                alpha=alpha,n_max=config.n_max,L_min=config.L_min,\n",
    "                                verbose=config.verbose, track_accept=config.track_accept,track_beta=config.track_beta,track_v_means=config.track_v_means,\n",
    "                                track_ratios=config.track_ratios,track_ess=config.track_ess,kappa_opt=config.kappa_opt\n",
    "                                ,gaussian =True,accept_spread=config.accept_spread, \n",
    "                                adapt_dt=config.adapt_dt, dt_decay=config.dt_decay,\n",
    "                                dt_gain=config.dt_gain,dt_min=config.dt_min,dt_max=config.dt_max,\n",
    "                                v_min_opt=config.v_min_opt,\n",
    "                                track_dt=config.track_dt,M_opt=config.M_opt,adapt_step=config.adapt_step,FT=config.FT,\n",
    "                                sig_dt=config.sig_dt, skip_mh=config.skip_mh,GV_opt=config.GV_opt\n",
    "                                )\n",
    "                                t1=time()-t\n",
    "                                if config.verbose>=2:\n",
    "                                    print(p_est)\n",
    "                                #finish_flag=res_dict['finished']\n",
    "                                \n",
    "                                if config.track_accept:\n",
    "                                    accept_rates_mcmc=res_dict['accept_rates_mcmc']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'accept_rates_mcmc_{i}.txt')\n",
    "                                    ,X=accept_rates_mcmc,)\n",
    "                                    x_T=np.arange(len(accept_rates_mcmc))\n",
    "                                    plt.plot(x_T,accept_rates_mcmc)\n",
    "                                    plt.savefig(os.path.join(log_path,f'accept_rates_mcmc_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                    \n",
    "\n",
    "                                if config.track_dt:\n",
    "                                    dts=res_dict['dts']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'dts_{i}.txt')\n",
    "                                    ,X=dts)\n",
    "                                    x_T=np.arange(len(dts))\n",
    "                                    plt.plot(x_T,dts)\n",
    "                                    plt.savefig(os.path.join(log_path,f'dts_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                \n",
    "                                \n",
    "                                times.append(t1)\n",
    "                                ests.append(p_est)\n",
    "                                calls.append(res_dict['calls'])\n",
    "                            times=np.array(times)\n",
    "                            ests = np.array(ests)\n",
    "                            calls=np.array(calls)\n",
    "                        \n",
    "                            mean_calls=calls.mean()\n",
    "                            std_est=ests.std()\n",
    "                            mean_est=ests.mean()\n",
    "                            std_rel=std_est/mean_est\n",
    "                            std_rel_adj=std_rel*mean_calls\n",
    "                            print(f\"Native PyTorch peformance\")\n",
    "                            print(f\"mean est:{ests.mean()}, std est:{ests.std()}\")\n",
    "                            print(f\"mean calls:{calls.mean()}\")\n",
    "                            print(f\"std. rel.:{std_rel}\")\n",
    "                            print(f\"std. rel. adj.:{std_rel*mean_calls}\")\n",
    "                            print(f\"mean time:{times.mean()}, std. time:{times.std()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('deep_learning_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc988435c4b631969eb5fce6943044c00d5bb2dcddaf96f4811676fc0db79e94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing EagerPy implementation of H-SMC on MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats as stat\n",
    "import numpy as np\n",
    "import eagerpy as ep\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import GPUtil\n",
    "import foolbox as fb\n",
    "import cpuinfo\n",
    "import pandas as pd\n",
    "from stat_reliability_measure.dev.utils import str2bool,str2floatList,str2intList,float_to_file_float,dichotomic_search\n",
    "from scipy.special import betainc\n",
    "from importlib import reload\n",
    "from stat_reliability_measure.home import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stat_reliability_measure.dev.smc.smc_ep as smc_ep\n",
    "import stat_reliability_measure.dev.ep_utils as e_u\n",
    "import stat_reliability_measure.dev.smc.smc_pyt as smc_pyt\n",
    "import stat_reliability_measure.dev.torch_utils as t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stat_reliability_measure.dev.ep_utils' from '/home/karim-tito/stat_reliability_measure/dev/ep_utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(smc_ep)\n",
    "reload(e_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name=\"smc_ep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    dataset='mnist'\n",
    "    N=100\n",
    "    N_range=[]\n",
    "    T=1\n",
    "    T_range=[]\n",
    "    L=1\n",
    "    L_range=[]\n",
    "    min_rate=0.2\n",
    "    \n",
    "    alpha=0.2\n",
    "    alpha_range=[]\n",
    "    ess_alpha=0.875\n",
    "    e_range=[]\n",
    "   \n",
    "    n_rep=120\n",
    "    \n",
    "    save_config=False \n",
    "    print_config=True\n",
    "    \n",
    "    x_min=0\n",
    "    x_max=1\n",
    "    x_mean=0\n",
    "    x_std=1\n",
    "\n",
    "    epsilons = None\n",
    "    eps_max=0.3\n",
    "    eps_min=0.2\n",
    "    eps_num=5\n",
    "    model_arch='CNN_custom'\n",
    "    model_path=None\n",
    "    export_to_onnx=False\n",
    "    use_attack=False\n",
    "    attack='PGD'\n",
    "    lirpa_bounds=False\n",
    "    download=True\n",
    "    train_model=False\n",
    "    \n",
    "    \n",
    "    noise_dist='uniform'\n",
    "    d=None\n",
    "    verbose=0\n",
    "    log_dir=None\n",
    "    aggr_res_path = None\n",
    "    update_agg_res=False\n",
    "    sigma=1\n",
    "    v1_kernel=True\n",
    "    torch_seed=None\n",
    "    gpu_name=None\n",
    "    cpu_name=None\n",
    "    cores_number=None\n",
    "    track_gpu=False\n",
    "    track_cpu=False\n",
    "    device=None\n",
    "    n_max=10000 \n",
    "    allow_multi_gpu=False\n",
    "    tqdm_opt=True\n",
    "    allow_zero_est=True\n",
    "    track_accept=True\n",
    "    track_calls=False\n",
    "    mh_opt=False\n",
    "    adapt_dt=False\n",
    "    adapt_dt_mcmc=False\n",
    "    target_accept=0.574\n",
    "    accept_spread=0.1\n",
    "    dt_decay=0.999\n",
    "    dt_gain=None\n",
    "    dt_min=1e-5\n",
    "    dt_max=0.7\n",
    "    v_min_opt=True\n",
    "    ess_opt=False\n",
    "    only_duplicated=True\n",
    "    np_seed=None\n",
    "    lambda_0=0.5\n",
    "    test2=False\n",
    "\n",
    "    s_opt=False\n",
    "    s=1\n",
    "    clip_s=True\n",
    "    s_min=1e-3\n",
    "    s_max=3\n",
    "    s_decay=0.95\n",
    "    s_gain=1.0001\n",
    "\n",
    "    track_dt=False\n",
    "    mult_last=True\n",
    "    linear=True\n",
    "\n",
    "    track_ess=True\n",
    "    track_beta=True\n",
    "    track_dt=True\n",
    "    track_v_means=True\n",
    "    track_ratios=False\n",
    "\n",
    "    kappa_opt=True\n",
    "\n",
    "    adapt_func='ESS'\n",
    "    M_opt = False\n",
    "    adapt_step=True\n",
    "    FT=True\n",
    "    sig_dt=0.02\n",
    "\n",
    "    batch_opt=True\n",
    "    track_finish=False\n",
    "    lirpa_cert=False\n",
    "    robust_model=False\n",
    "    robust_eps=0.1\n",
    "    load_batch_size=100 \n",
    "    nb_epochs= 10\n",
    "    adversarial_every=1\n",
    "    data_dir=ROOT_DIR+\"/data\"\n",
    "    p_ref_compute=False\n",
    "    input_start=0\n",
    "    input_stop=None\n",
    "\n",
    "    gaussian_latent=True\n",
    "\n",
    "    model_dir=None \n",
    "    L_min=1\n",
    "    GK_opt=False\n",
    "    GV_opt=False\n",
    "    g_target=0.8\n",
    "    skip_mh=False\n",
    "    force_train=False\n",
    "    killing=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reliability experiments on architecture CNN_custom trained on mnist.\n",
      "Testing uniform noise pertubatin with epsilon in [0.2        0.22133638 0.24494897 0.2710806  0.3       ]\n"
     ]
    }
   ],
   "source": [
    "if config.model_dir is None:\n",
    "    config.model_dir=os.path.join(ROOT_DIR+\"/models/\",config.dataset)\n",
    "    if not os.path.exists(config.model_dir):\n",
    "        os.mkdir(config.model_dir)\n",
    "\n",
    "config.d = t_u.datasets_dims[config.dataset]\n",
    "color_dataset=config.dataset in ('cifar10','cifar100','imagenet') \n",
    "#assert config.adapt_func.lower() in smc_pyt.supported_beta_adapt.keys(),f\"select adaptive function in {smc_pyt.supported_beta_adapt.keys}\"\n",
    "#adapt_func=smc_pyt.supported_beta_adapt[config.adapt_func.lower()]\n",
    "\n",
    "if config.adapt_func.lower()=='simp_ess':\n",
    "    adapt_func = lambda beta,v : smc_pyt.nextBetaSimpESS(beta_old=beta,v=v,lambda_0=config.lambda_0,max_beta=1e6)\n",
    "elif config.adapt_func.lower()=='simp':\n",
    "    adapt_func = lambda beta,v: smc_pyt.SimpAdaptBetaPyt(beta,v,config.g_target,v_min_opt=config.v_min_opt)\n",
    "prblm_str=config.dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if len(config.e_range)==0:\n",
    "    config.e_range= [config.ess_alpha]\n",
    "\n",
    "if config.input_stop is None:\n",
    "    config.input_stop=config.input_start+1\n",
    "else:\n",
    "    assert config.input_start<config.input_stop,\"/!\\ input start must be strictly lower than input stop\"\n",
    "if len(config.N_range)==0:\n",
    "    config.N_range= [config.N]\n",
    "\n",
    "if config.noise_dist is not None:\n",
    "    config.noise_dist=config.noise_dist.lower()\n",
    "\n",
    "if config.noise_dist not in ['uniform','gaussian']:\n",
    "    raise NotImplementedError(\"Only uniform and Gaussian distributions are implemented.\")\n",
    "\n",
    "if len(config.T_range)==0:\n",
    "    config.T_range= [config.T]\n",
    "\n",
    "if len(config.L_range)==0:\n",
    "    config.L_range= [config.L]\n",
    "if len(config.alpha_range)==0:\n",
    "    config.alpha_range= [config.alpha]\n",
    "\n",
    "\n",
    "if not config.allow_multi_gpu:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "\n",
    "if config.torch_seed is None:\n",
    "    config.torch_seed=int(time())\n",
    "torch.manual_seed(seed=config.torch_seed)\n",
    "\n",
    "if config.np_seed is None:\n",
    "    config.np_seed=int(time())\n",
    "torch.manual_seed(seed=config.np_seed)\n",
    "\n",
    "\n",
    "\n",
    "if config.track_gpu:\n",
    "    gpus=GPUtil.getGPUs()\n",
    "    if len(gpus)>1:\n",
    "        print(\"Multi gpus detected, only the first GPU will be tracked.\")\n",
    "    config.gpu_name=gpus[0].name\n",
    "\n",
    "if config.track_cpu:\n",
    "    config.cpu_name=cpuinfo.get_cpu_info()[[key for key in cpuinfo.get_cpu_info().keys() if 'brand' in key][0]]\n",
    "    config.cores_number=os.cpu_count()\n",
    "\n",
    "\n",
    "if config.device is None:\n",
    "    config.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
    "    if config.verbose>=5:\n",
    "        print(config.device)\n",
    "    device=config.device\n",
    "else:\n",
    "    device=config.device\n",
    "\n",
    "d=config.d\n",
    "#epsilon=config.epsilon\n",
    "\n",
    "if config.log_dir is None:\n",
    "    config.log_dir=os.path.join(ROOT_DIR+'/logs',config.dataset+'_tests')\n",
    "if not os.path.exists(ROOT_DIR+'/logs'):\n",
    "    os.mkdir(ROOT_DIR+'/logs')  \n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.mkdir(config.log_dir)\n",
    "\n",
    "results_path=os.path.join(config.log_dir,'results.csv')\n",
    "if os.path.exists(results_path):\n",
    "    results_g=pd.read_csv(results_path)\n",
    "else:\n",
    "    results_g=pd.DataFrame(columns=['mean_est','mean_time','mean_err','stdtime','std_est','T','N','rho','alpha','n_rep','min_rate','method'])\n",
    "    results_g.to_csv(results_path,index=False)\n",
    "raw_logs = os.path.join(config.log_dir,'raw_logs/')\n",
    "if not os.path.exists(raw_logs):\n",
    "    os.mkdir(raw_logs)\n",
    "raw_logs_path=os.path.join(config.log_dir,'raw_logs/'+method_name)\n",
    "if not os.path.exists(raw_logs_path):\n",
    "    os.mkdir(raw_logs_path)\n",
    "\n",
    "loc_time= datetime.today().isoformat().split('.')[0]\n",
    "log_name=method_name+'_'+'_'+loc_time\n",
    "exp_log_path=os.path.join(raw_logs_path,log_name)\n",
    "if os.path.exists(path=exp_log_path):\n",
    "    exp_log_path = exp_log_path+'_'+str(np.random.randint(low=0,high=9))\n",
    "os.mkdir(path=exp_log_path)\n",
    "\n",
    "# if config.aggr_res_path is None:\n",
    "#     aggr_res_path=os.path.join(config.log_dir,'agg_res.csv')\n",
    "# else:\n",
    "#     aggr_res_path=config.aggr_res_path\n",
    "\n",
    "if config.dt_gain is None:\n",
    "    config.dt_gain=1/config.dt_decay\n",
    "\n",
    "\n",
    "\n",
    "if config.epsilons is None:\n",
    "    log_min,log_max=np.log(config.eps_min),np.log(config.eps_max)\n",
    "    log_line=np.linspace(start=log_min,stop=log_max,num=config.eps_num)\n",
    "    config.epsilons=np.exp(log_line)\n",
    "\n",
    "param_ranges = [config.N_range,config.T_range,config.L_range,config.e_range,config.alpha_range]\n",
    "param_lens=np.array([len(l) for l in param_ranges])\n",
    "nb_runs= np.prod(param_lens)\n",
    "\n",
    "mh_str=\"adjusted\" \n",
    "method=method_name+'_'+mh_str\n",
    "save_every = 1\n",
    "x_min=0\n",
    "x_max=1\n",
    "#adapt_func= smc_pyt.ESSAdaptBetaPyt if config.ess_opt else smc_pyt.SimpAdaptBetaPyt\n",
    "num_classes=t_u.datasets_num_c[config.dataset.lower()]\n",
    "print(f\"Running reliability experiments on architecture {config.model_arch} trained on {config.dataset}.\")\n",
    "print(f\"Testing uniform noise pertubatin with epsilon in {config.epsilons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = t_u.get_loader(train=False,data_dir=config.data_dir,download=config.download\n",
    ",dataset=config.dataset,batch_size=config.load_batch_size,\n",
    "           x_mean=None,x_std=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, model_shape,model_name=t_u.get_model(config.model_arch, robust_model=config.robust_model, robust_eps=config.robust_eps,\n",
    "    nb_epochs=config.nb_epochs,model_dir=config.model_dir,data_dir=config.data_dir,test_loader=test_loader,device=config.device,\n",
    "    download=config.download,dataset=config.dataset, force_train=config.force_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_correct,label_correct,accuracy=t_u.get_correct_x_y(data_loader=test_loader,device=device,model=model)\n",
    "if config.verbose>=2:\n",
    "    print(f\"model accuracy on test batch:{accuracy}\")\n",
    "    config.x_mean=t_u.datasets_means[config.dataset]\n",
    "config.x_std=t_u.datasets_stds[config.dataset]\n",
    "if config.use_attack:\n",
    "\n",
    "    fmodel = fb.PyTorchModel(model, bounds=(0,1),device=device)\n",
    "    attack=fb.attacks.LinfPGD()\n",
    "    #un-normalize data before performing attack\n",
    "    _, advs, success = attack(fmodel, X_correct[config.input_start:config.input_stop], \n",
    "    label_correct[config.input_start:config.input_stop], epsilons=config.epsilons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Normalize(mean=0, std=1)\n",
       "  (1): CNN_custom(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (activation): ReLU()\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (activation2): ReLU()\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (linear1): Linear(in_features=3136, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "inp_indices=np.arange(start=config.input_start,stop=config.input_stop)\n",
    "normal_dist=torch.distributions.Normal(loc=0, scale=1.)\n",
    "run_nb=0\n",
    "iterator= tqdm(range(config.n_rep))\n",
    "exp_res=[]\n",
    "clip_min=0\n",
    "clip_max=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test EagerPy H-SMC implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in inp_indices:\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        x_0,y_0 = X_correct[l], label_correct[l]\n",
    "\n",
    "   \n",
    "    for idx in range(len(config.epsilons)):\n",
    "        \n",
    "        \n",
    "        epsilon = config.epsilons[idx]\n",
    "        pgd_success= (success[idx][l]).item() if config.use_attack else None \n",
    "        p_l,p_u=None,None\n",
    "        if config.lirpa_bounds:\n",
    "            from stat_reliability_measure.dev.lirpa_utils import get_lirpa_bounds\n",
    "            # Step 2: define perturbation. Here we use a Linf perturbation on input image.\n",
    "            p_l,p_u=get_lirpa_bounds(x_0=x_0,y_0=y_0,model=model,epsilon=epsilon,\n",
    "            num_classes=num_classes,noise_dist=config.noise_dist,a=config.a,device=config.device)\n",
    "            p_l,p_u=p_l.item(),p_u.item()\n",
    "        lirpa_safe=None\n",
    "        if config.lirpa_cert:\n",
    "            assert config.noise_dist.lower()=='uniform',\"Formal certification only makes sense for uniform distributions\"\n",
    "            from stat_reliability_measure.dev.lirpa_utils import get_lirpa_cert\n",
    "            lirpa_safe=get_lirpa_cert(x_0=x_0,y_0=y_0,model=model,epsilon=epsilon,\n",
    "            num_classes=num_classes,device=config.device)\n",
    "\n",
    "        \n",
    "        \n",
    "        if config.gaussian_latent:\n",
    "            gen = lambda N: torch.randn(size=(N,d),device=config.device)\n",
    "        else:\n",
    "            gen= lambda N: (2*torch.rand(size=(N,d), device=device )-1)\n",
    "        low=torch.max(x_0-epsilon, torch.tensor([x_min]).cuda())\n",
    "        high=torch.min(x_0+epsilon, torch.tensor([x_max]).cuda())  \n",
    "        V_ = lambda X: t_u.V_pyt(X,x_0=x_0,model=model,low=low,high=high,target_class=y_0,gaussian_latent=config.gaussian_latent)\n",
    "        gradV_ = lambda X: t_u.gradV_pyt(X,x_0=x_0,model=model,low=low,high=high, target_class=y_0,gaussian_latent=config.gaussian_latent)\n",
    "        gradV_ep = lambda X: ep.astensor(gradV_(X.raw))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stat_reliability_measure.dev.torch_utils' from '/home/karim-tito/stat_reliability_measure/dev/torch_utils.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(e_u)\n",
    "reload(smc_ep)\n",
    "reload(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/1\n",
      "Starting simulations with model:CNN_custom_mnist img_idx:0,eps=0.3,ess_t:0.875,T:1,alpha:0.2,N:100,L:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:10<?, ?it/s]\n",
      "100%|██████████| 120/120 [00:57<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean est:1.57380482646019e-07, std est:1.590876341684067e-07\n",
      "mean calls:5532.30971883138\n",
      "std. rel.:1.0108472886452344\n",
      "std. rel. adj.:5592.32027922638\n",
      "mean time:0.33678967754046124, std. time:0.03798244040352301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ess_t in config.e_range:\n",
    "            if config.adapt_func.lower()=='ess':\n",
    "                adapt_func = lambda beta,v : smc_pyt.nextBetaESS(beta_old=beta,v=v,ess_alpha=ess_t,max_beta=1e6)\n",
    "            for T in config.T_range:\n",
    "                for L in config.L_range:\n",
    "                    for alpha in config.alpha_range:       \n",
    "                        for N in config.N_range:\n",
    "                            loc_time= datetime.today().isoformat().split('.')[0]\n",
    "                            log_name=method_name+f'_N_{N}_T_{T}_L_{L}_a_{float_to_file_float(alpha)}_ess_{float_to_file_float(ess_t)}'+'_'+loc_time.split('_')[0]\n",
    "                            log_path=os.path.join(exp_log_path,log_name)\n",
    "                            if os.path.exists(log_path):\n",
    "                                log_path = log_path + '_'+str(np.random.randint(low=0,high =10))\n",
    "                            \n",
    "                            \n",
    "                            os.mkdir(path=log_path)\n",
    "                            run_nb+=1\n",
    "                            print(f'Run {run_nb}/{nb_runs}')\n",
    "                            times=[]\n",
    "                            ests = []\n",
    "                            calls=[]\n",
    "                            finished_flags=[]\n",
    "                            iterator= tqdm(range(config.n_rep)) if config.tqdm_opt else range(config.n_rep)\n",
    "                            print(f\"Starting simulations with model:{model_name} img_idx:{l},eps={epsilon},ess_t:{ess_t},T:{T},alpha:{alpha},N:{N},L:{L}\")\n",
    "                            for i in iterator:\n",
    "                                t=time()\n",
    "                                p_est,res_dict,=smc_pyt.SamplerSMC(gen=gen,V= V_,gradV=gradV_,adapt_func=adapt_func,min_rate=config.min_rate,N=N,T=T,L=L,\n",
    "                                alpha=alpha,n_max=config.n_max,L_min=config.L_min,\n",
    "                                verbose=config.verbose, track_accept=config.track_accept,track_beta=config.track_beta,track_v_means=config.track_v_means,\n",
    "                                track_ratios=config.track_ratios,track_ess=config.track_ess,kappa_opt=config.kappa_opt\n",
    "                                ,gaussian =True,accept_spread=config.accept_spread, \n",
    "                                adapt_dt=config.adapt_dt, dt_decay=config.dt_decay,\n",
    "                                dt_gain=config.dt_gain,dt_min=config.dt_min,dt_max=config.dt_max,\n",
    "                                v_min_opt=config.v_min_opt,\n",
    "                                track_dt=config.track_dt,M_opt=config.M_opt,adapt_step=config.adapt_step,FT=config.FT,\n",
    "                                sig_dt=config.sig_dt, skip_mh=config.skip_mh,GV_opt=config.GV_opt\n",
    "                                )\n",
    "                                t1=time()-t\n",
    "                                if config.verbose>=2:\n",
    "                                    print(p_est)\n",
    "                                #finish_flag=res_dict['finished']\n",
    "                                \n",
    "                                if config.track_accept:\n",
    "                                    accept_rates_mcmc=res_dict['accept_rates_mcmc']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'accept_rates_mcmc_{i}.txt')\n",
    "                                    ,X=accept_rates_mcmc,)\n",
    "                                    x_T=np.arange(len(accept_rates_mcmc))\n",
    "                                    plt.plot(x_T,accept_rates_mcmc)\n",
    "                                    plt.savefig(os.path.join(log_path,f'accept_rates_mcmc_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                    \n",
    "\n",
    "                                if config.track_dt:\n",
    "                                    dts=res_dict['dts']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'dts_{i}.txt')\n",
    "                                    ,X=dts)\n",
    "                                    x_T=np.arange(len(dts))\n",
    "                                    plt.plot(x_T,dts)\n",
    "                                    plt.savefig(os.path.join(log_path,f'dts_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                \n",
    "                                \n",
    "                                times.append(t1)\n",
    "                                ests.append(p_est)\n",
    "                                calls.append(res_dict['calls'])\n",
    "                            times=np.array(times)\n",
    "                            ests = np.array(ests)\n",
    "                            calls=np.array(calls)\n",
    "                        \n",
    "                            mean_calls=calls.mean()\n",
    "                            std_est=ests.std()\n",
    "                            mean_est=ests.mean()\n",
    "                            std_rel=std_est/mean_est\n",
    "                            std_rel_adj=std_rel*mean_calls\n",
    "                            print(f\"mean est:{ests.mean()}, std est:{ests.std()}\")\n",
    "                            print(f\"mean calls:{calls.mean()}\")\n",
    "                            print(f\"std. rel.:{std_rel}\")\n",
    "                            print(f\"std. rel. adj.:{std_rel*mean_calls}\")\n",
    "                            print(f\"mean time:{times.mean()}, std. time:{times.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/1\n",
      "Starting simulations with model:CNN_custom_mnist img_idx:0,eps=0.3,ess_t:0.875,T:1,alpha:0.2,N:100,L:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [01:00<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean est:1.7509553273213168e-07, std est:1.6930038170390467e-07\n",
      "mean calls:5518.9628999999995\n",
      "std. rel.:0.9669029190076902\n",
      "std. rel. adj.:5336.301337905146\n",
      "mean time:0.36244499882062275, std. time:0.043996984515696363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ess_t in config.e_range:\n",
    "            if config.adapt_func.lower()=='ess':\n",
    "                adapt_func = lambda beta,v : smc_ep.nextBetaESS(beta_old=beta,v=v,ess_alpha=ess_t,max_beta=1e6)\n",
    "            for T in config.T_range:\n",
    "                for L in config.L_range:\n",
    "                    for alpha in config.alpha_range:       \n",
    "                        for N in config.N_range:\n",
    "                            loc_time= datetime.today().isoformat().split('.')[0]\n",
    "                            log_name=method_name+f'_N_{N}_T_{T}_L_{L}_a_{float_to_file_float(alpha)}_ess_{float_to_file_float(ess_t)}'+'_'+loc_time.split('_')[0]\n",
    "                            log_path=os.path.join(exp_log_path,log_name)\n",
    "                            if os.path.exists(log_path):\n",
    "                                log_path = log_path + '_'+str(np.random.randint(low=0,high =10))\n",
    "                            \n",
    "                            \n",
    "                            os.mkdir(path=log_path)\n",
    "                            run_nb+=1\n",
    "                            print(f'Run {run_nb}/{nb_runs}')\n",
    "                            times=[]\n",
    "                            ests = []\n",
    "                            calls=[]\n",
    "                            finished_flags=[]\n",
    "                            iterator= tqdm(range(config.n_rep)) if config.tqdm_opt else range(config.n_rep)\n",
    "                            print(f\"Starting simulations with model:{model_name} img_idx:{l},eps={epsilon},ess_t:{ess_t},T:{T},alpha:{alpha},N:{N},L:{L}\")\n",
    "                            for i in iterator:\n",
    "                                t=time()\n",
    "                                p_est,res_dict,=smc_ep.SamplerSMC(gen=gen,V= V_,gradV=gradV_ep,adapt_func=adapt_func,min_rate=config.min_rate,N=N,T=T,L=L,\n",
    "                                alpha=alpha,n_max=config.n_max,L_min=config.L_min,\n",
    "                                verbose=config.verbose, track_accept=config.track_accept,track_beta=config.track_beta,track_v_means=config.track_v_means,\n",
    "                                track_ratios=config.track_ratios,track_ess=config.track_ess,kappa_opt=config.kappa_opt\n",
    "                                ,gaussian =True,accept_spread=config.accept_spread, \n",
    "                                adapt_dt=config.adapt_dt, dt_decay=config.dt_decay,\n",
    "                                dt_gain=config.dt_gain,dt_min=config.dt_min,dt_max=config.dt_max,\n",
    "                                v_min_opt=config.v_min_opt,\n",
    "                                track_dt=config.track_dt,M_opt=config.M_opt,adapt_step=config.adapt_step,FT=config.FT,\n",
    "                                sig_dt=config.sig_dt, skip_mh=config.skip_mh,GV_opt=config.GV_opt\n",
    "                                )\n",
    "                                t1=time()-t\n",
    "\n",
    "                                if config.verbose>=2:\n",
    "                                    print(p_est)\n",
    "                                #finish_flag=res_dict['finished']\n",
    "                                \n",
    "                                if config.track_accept:\n",
    "                                    accept_rates_mcmc=res_dict['accept_rates_mcmc']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'accept_rates_mcmc_{i}.txt')\n",
    "                                    ,X=accept_rates_mcmc,)\n",
    "                                    x_T=np.arange(len(accept_rates_mcmc))\n",
    "                                    plt.plot(x_T,accept_rates_mcmc)\n",
    "                                    plt.savefig(os.path.join(log_path,f'accept_rates_mcmc_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                    \n",
    "\n",
    "                                if config.track_dt:\n",
    "                                    dts=res_dict['dts']\n",
    "                                    np.savetxt(fname=os.path.join(log_path,f'dts_{i}.txt')\n",
    "                                    ,X=dts)\n",
    "                                    x_T=np.arange(len(dts))\n",
    "                                    plt.plot(x_T,dts)\n",
    "                                    plt.savefig(os.path.join(log_path,f'dts_{i}.png'))\n",
    "                                    plt.close()\n",
    "                                \n",
    "                                \n",
    "                                times.append(t1)\n",
    "                                ests.append(p_est)\n",
    "                                calls.append(res_dict['calls'])\n",
    "                            times=np.array(times)\n",
    "                            ests = np.array(ests)\n",
    "                            calls=np.array(calls)\n",
    "                        \n",
    "                            mean_calls=calls.mean()\n",
    "                            std_est=ests.std()\n",
    "                            mean_est=ests.mean()\n",
    "                            std_rel=std_est/mean_est\n",
    "                            std_rel_adj=std_rel*mean_calls\n",
    "                            print(f\"mean est:{ests.mean()}, std est:{ests.std()}\")\n",
    "                            print(f\"mean calls:{calls.mean()}\")\n",
    "                            print(f\"std. rel.:{std_rel}\")\n",
    "                            print(f\"std. rel. adj.:{std_rel*mean_calls}\")\n",
    "                            print(f\"mean time:{times.mean()}, std. time:{times.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('deep_learning_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc988435c4b631969eb5fce6943044c00d5bb2dcddaf96f4811676fc0db79e94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

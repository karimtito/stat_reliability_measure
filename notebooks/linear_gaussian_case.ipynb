{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import numpy.linalg as LA\n",
    "import scipy.stats as stat\n",
    "from langevin_smc import TimeStep, LangevinSMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import betainc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Case: two distributions with different means and same covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. No models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiallazing random seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "d = 1000\n",
    "R = 10 #distance between the means\n",
    "mu_0,mu_1 = np.zeros(d),np.zeros(d)\n",
    "mu_1[0]=np.sqrt(R)\n",
    "#m = np.random.normal(size = d)\n",
    "#mu_1 = m/np.linalg.norm(m)\n",
    "\n",
    "#Sigma = stat.wishart.rvs(df= d, scale = np.eye(d))\n",
    "Sigma = (R/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating data\n",
    "n_sample = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "a=5.\n",
    "isinstance(a,float) or isinstance(a,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6.219080303309307e-216"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "import sampling_tools\n",
    "gene_d = lambda N: Sigma*np.random.normal(size =(N,d)) +mu_1\n",
    "\n",
    "phi_ = lambda x: x.dot(mu_1)/(LA.norm(x)*LA.norm(mu_1))\n",
    "\n",
    "h_ = lambda x: float(x[0]>R)\n",
    "h_0 = lambda x: float(x[0]>1)\n",
    "h_lab = lambda x: np.array(x[0]>5, dtype=np.float)\n",
    "\n",
    "w_d = lambda x: sampling_tools.gaussian_density_ratio(x, m_1=mu_1,C_0 = 1/Sigma, C_1=1/Sigma)\n",
    "\n",
    "y = gene_d(1000)\n",
    "Phi = (np.apply_along_axis(phi_, 1, y))\n",
    "W = (np.apply_along_axis(w_d, 1, y))\n",
    "(W[:,None]*Phi.reshape(-1,1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportanceSampling(gen, phi, w, N=1000, alpha = 0.95):\n",
    "    \"\"\" Importance sampling estimator \n",
    "        Args:\n",
    "            gen: generator of iid samples X_i under alternative law      [fun]\n",
    "            \n",
    "            phi: score function                                   [fun]\n",
    "            w: weight function, typically a ratio of densities    [fun]\n",
    "            \n",
    "            N: number of samples                                  [1x1] (1000)\n",
    "            \n",
    "            alpha: level of confidence interval                   [1x1] (0.95)\n",
    "            verbose: level of verbosity                           [1x1] (1)\n",
    "\n",
    "        Returns:\n",
    "            E_est: estimated expectancy\n",
    "            s_out: a dictionary containing additional output data\n",
    "            -s_out['Var_est']: estimated variance\n",
    "            -s_out['CI_est']: estimated confidence of interval\n",
    "            \n",
    "    \"\"\"\n",
    "    q = -stat.norm.ppf((1-alpha)/2)\n",
    "    d = gen(1).shape[-1]\n",
    "    Y = gen(N) #array of dim (N,d)\n",
    "    W = np.apply_along_axis(w, 1, Y) #weighting vectors\n",
    "    Phi = np.apply_along_axis(phi, 1, Y)\n",
    "    if Phi.ndim<=1:\n",
    "        Phi = Phi.reshape(-1,1)      #forces Phi to be two dimensional for compatibility with vectorial phi functions\n",
    "    \n",
    "    E_est = (W[:,None]*Phi).mean() \n",
    "    Var_est = (((W[:,None]*Phi)**2).mean(0)-E_est**2)/N\n",
    "    CI_est = E_est*np.array([1,1]) + q*np.sqrt(Var_est)*np.array([-1,1])\n",
    "\n",
    "    s_out = {\"Var_est\": Var_est, \"CI_est\": CI_est}\n",
    "    return E_est, s_out\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stat' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c920a312319f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mE_true\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stat' is not defined"
     ]
    }
   ],
   "source": [
    "E_true= stat.norm.sf(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_true= stat.norm.sf(5)\n",
    "E_est, s_out = ImportanceSampling(gen=gene_d, phi=h_lab, w=w_d, N=400000, alpha = 0.95)\n",
    "CI_in = (E_true>= s_out[\"CI_est\"][0]) and (E_true< s_out[\"CI_est\"][1])\n",
    "mape = np.abs(E_true-E_est)/E_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "E_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.866515718791933e-07"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "E_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model test for Langevin-based SMC "
   ]
  },
  {
   "source": [
    "$X \\sim  \\mathcal{U}(B_{\\mathbb{R}^d}(0,\\epsilon))$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 15\n",
    "epsilon = 1\n",
    "c = 0.5\n",
    "h = 1-c\n",
    "e_1 = np.array([1]+[0]*(d-1))\n",
    "P_target = betainc(0.5*(d+1),0.5,(2*epsilon*h-h**2)/(epsilon**2))\n",
    "V_batch = lambda X: np.clip(c-X[:,0],a_min=0, a_max = np.inf)\n",
    "gradV_batch = lambda X: -e_1[None]*(X[:,0]<c)[:,None] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.034599676728248596"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "P_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_ball_gen(N,R,d):\n",
    "    x = np.random.normal(0,1,(N,d))  \n",
    "    norms = np.linalg.norm(x,axis =1)[:,None]\n",
    "    r = (R*np.random.uniform(size =(N,1)))**(1.0/d)\n",
    "    x= r*x/norms\n",
    "    return x"
   ]
  },
  {
   "source": [
    "### Naive Monte Carlo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_mc = 1000\n",
    "X = uniform_ball_gen(N_mc,epsilon,d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Relative error of naive MC estimator :0.42195991722456816\n"
     ]
    }
   ],
   "source": [
    "P_est_MC = np.mean(X[:,0]>c)\n",
    "error_MC = np.abs(P_target-P_est_MC)/P_target\n",
    "del X\n",
    "print(f\"Relative error of naive MC estimator :{error_MC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_ball(X, R):\n",
    "    X_norms = np.linalg.norm(X, axis =1)[:,None]\n",
    "    X_in_ball = X_norms<=R\n",
    "    return R*X/X_norms*(~X_in_ball)+(X_in_ball)*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjct_epsilon = lambda X: project_ball(X, R=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_langevin_kernel(X,gradV,delta_t,beta, projection=prjct_epsilon):\n",
    "    G_noise = np.random.normal(size = X.shape)\n",
    "    X_new =projection(X-delta_t*gradV(X)+np.sqrt(2*delta_t/beta)*G_noise)\n",
    "    return X_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = np.linspace(0,1000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_gen_epsilon = lambda N: uniform_ball_gen(N,R=epsilon, d=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.99148454, 0.97384045, 0.98236057, 0.94251624])"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "LA.norm(uniform_gen_epsilon(4),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "LangevinSMC(uniform_gen_epsilon,  V=V_batch, gradV= gradV_batch, l_kernel = projected_langevin_kernel,betas = betas[1:],alpha = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = uniform_gen_epsilon\n",
    "V=V_batch\n",
    "gradV= gradV_batch\n",
    "l_kernel = projected_langevin_kernel\n",
    "betas = betas\n",
    "N=1000\n",
    "alpha = 100\n",
    "T=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gen(N) # generate N samples\n",
    "\n",
    "w= (1/N)*np.ones(N)\n",
    "v = V(X) # computes their potentials\n",
    "Count_h = N # Number of calls to function V or it's  gradient\n",
    "delta_t = alpha*TimeStep(V,X,gradV)\n",
    "\n",
    "g=1\n",
    "beta_old = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "v min:0.0, ratio adv. 0.018\nLocal level proba :2626987131094047.0\nv min:0.0, ratio adv. 0.982\nLocal level proba :115064952667246.42\nv min:0.0, ratio adv. 0.018\nLocal level proba :113093669167720.98\nv min:0.0, ratio adv. 0.982\nLocal level proba :5471645875294.479\nv min:0.0, ratio adv. 0.018\nLocal level proba :5375183937811.064\nv min:0.0, ratio adv. 0.982\nLocal level proba :284625809158.4497\nv min:0.0, ratio adv. 0.018\nLocal level proba :279626351966.1945\nv min:0.0, ratio adv. 0.982\nLocal level proba :15089769337.036264\nv min:0.0, ratio adv. 0.019\nLocal level proba :14833381267.16211\n"
     ]
    }
   ],
   "source": [
    "for beta in betas[1:10]:\n",
    "    G = np.exp(-(beta-beta_old)*v) #computes current value fonction\n",
    "            \n",
    "    g*= G.mean()\n",
    "    #G_tilde = G/G.sum()\n",
    "    #w = w * G_tilde #updates weights\n",
    "\n",
    "    for t in range(T):\n",
    "        X=projected_langevin_kernel(X, gradV, delta_t, beta)\n",
    "\n",
    "    v = V(X)\n",
    "    print(f'v min:{v.min()}, ratio adv. {(v<=0).mean()}')\n",
    "    print(f'Local level proba :{g}')\n",
    "    beta_old = beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.07052322, 0.07094231, 0.08181071, 0.07809875, 0.10069065,\n",
       "       0.05985575, 0.08632759, 0.08861802, 0.08247472, 0.07598067,\n",
       "       0.0761216 , 0.06498536, 0.11386722, 0.08851727, 0.09720747,\n",
       "       0.08232568, 0.07118774, 0.08850645, 0.0900826 , 0.07374759,\n",
       "       0.07420802, 0.07007252, 0.08040534, 0.06152253, 0.06771813,\n",
       "       0.08854958, 0.07390733, 0.09509416, 0.10297033, 0.07731748,\n",
       "       0.0892293 , 0.09900778, 0.05725562, 0.0587809 , 0.08284706,\n",
       "       0.0869259 , 0.07535465, 0.08564974, 0.07698647, 0.07712493,\n",
       "       0.07146362, 0.06693976, 0.06936882, 0.0924148 , 0.09944258,\n",
       "       0.07090218, 0.08288347, 0.07862621, 0.04922605, 0.07935632,\n",
       "       0.08774705, 0.08453352, 0.07644145, 0.06162055, 0.10246571,\n",
       "       0.09717194, 0.06755741, 0.08534813, 0.08315969, 0.08378221,\n",
       "       0.08634974, 0.1185489 , 0.0710409 , 0.08668215, 0.10094678,\n",
       "       0.08106466, 0.10396602, 0.081824  , 0.09271306, 0.08380309,\n",
       "       0.09684894, 0.10090763, 0.08310908, 0.09092459, 0.09560506,\n",
       "       0.06744442, 0.07526214, 0.06948051, 0.05428745, 0.07134989,\n",
       "       0.06891995, 0.08145106, 0.0982363 , 0.0904019 , 0.04913764,\n",
       "       0.09849695, 0.07755564, 0.07367268, 0.08396335, 0.0755927 ,\n",
       "       0.09514678, 0.07054924, 0.07731087, 0.10418337, 0.09873582,\n",
       "       0.09945511, 0.09108643, 0.07681708, 0.0968082 , 0.06608581])"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.27381338429801116"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "v.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.99999921, 0.9999994 , 0.99999914, 0.99999895, 0.99999885,\n",
       "       0.99999885, 0.99999936, 0.9999993 , 0.99999951, 0.99999886,\n",
       "       0.9999994 , 0.99999905, 0.99999935, 0.99999883, 0.99999893,\n",
       "       0.99999939, 0.99999945, 0.99999926, 0.99999927, 0.99999907,\n",
       "       0.99999941, 0.999999  , 0.9999991 , 0.99999887, 0.99999933,\n",
       "       0.9999993 , 0.99999913, 0.99999896, 0.99999918, 0.99999894,\n",
       "       0.99999937, 0.99999958, 0.99999899, 0.99999903, 0.99999936,\n",
       "       0.99999941, 0.99999884, 0.99999927, 0.99999889, 0.99999948,\n",
       "       0.99999907, 0.99999904, 0.99999924, 0.99999934, 0.99999886,\n",
       "       0.99999905, 0.99999933, 0.99999932, 0.99999897, 0.99999896,\n",
       "       0.99999937, 0.99999932, 0.99999923, 0.99999902, 0.99999924,\n",
       "       0.99999926, 0.9999992 , 0.9999991 , 0.99999945, 0.99999863,\n",
       "       0.9999994 , 0.99999953, 0.99999871, 0.99999931, 0.99999915,\n",
       "       0.99999914, 0.99999932, 0.99999919, 0.99999938, 0.99999878,\n",
       "       0.99999961, 0.99999884, 0.99999933, 0.99999898, 0.99999904,\n",
       "       0.99999922, 0.99999902, 0.99999977, 0.9999991 , 0.99999944,\n",
       "       0.99999893, 0.9999997 , 0.99999957, 0.99999948, 0.99999958,\n",
       "       0.99999925, 0.9999995 , 0.99999861, 0.99999925, 0.99999972,\n",
       "       0.99999921, 0.99999894, 0.99999926, 0.99999958, 0.99999953,\n",
       "       0.99999902, 0.99999948, 0.99999932, 0.99999941, 0.99999934])"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (deep_learning)",
   "language": "python",
   "name": "deep_learning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}